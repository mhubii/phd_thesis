Automation is increasingly integrating into our daily routines, with autonomous vehicles, vacuum cleaners, drones, and industrial arms exhibiting notable advancements in autonomy. These developments owe much to the significant boost in parallel computing capabilities and the widespread use of neural networks. However, in fields such as surgery and robotic surgery, automation progress lags somewhat behind other sectors. Apart from challenges posed by unstructured environments, regulatory constraints, and ethical considerations, this thesis contends that technical barriers also impede further advancements. As indicated by the thesis title, \textit{Data-driven Robotic Endoscope Automation}, robotic endoscope automation holds immediate relevance in this context due to its relative simplicity. Traditional rule-based methods assume a tool-following pattern for camera motion, which lacks clinical validation. The adoption of modern data-driven approaches could facilitate the learning of more intricate control policies. However, two primary technical obstacles hinder progress in this area: the absence of state-action pairs, rendering the application of modern imitation learning techniques impossible, and the lack of clear pathways toward automation in currently non-robotic surgeries.

In this thesis, we address the hurdles through developing methods that extract camera motion control policies from surgeon-held endoscopes, as well as methods for executing the policies on serial manipulators. First, we introduce a novel marker-free unified hand-eye calibration procedure that allows for precise robot localization from RGB-D images in a clinical setting whilst keeping the clinical workflow unaltered. This is a crucial prerequisite for spatial awareness and to control robots autonomously in a surgical theater. We verify the proposed method during an in-vivo experiment and demonstrate successful application. Second, we derive a visual servo for image-based control that does not require any explicit tool and camera position nor any explicit depth information. The proposed method works regardless of the relative patient coordinate frame and is safe for clinical use by design. We deploy the approach in a semi-autonomous scenario.
%however find that it suffers from temporality assumptions.
Third, we find efficient means for extracting state-action pairs from retrospective videos of laparoscopic surgery videos (surgeon-held or robotic) through a novel data augmentation method in a supervised learning procedure. The proposed method is indeed so robust that it transfers from videos of robotic laparoscopic surgery to classical laparoscopic interventions. Fourth, we introduce a fully self-supervised pipeline to learn to predict actions from the observed states through generating pseudo-ground truth via the action extraction. Fifth, we contribute significantly to robot driver infrastructure and ecosystem embedding in an attempt to make advancements accessible to a greater community and in return benefit from community contributed developments for accelerate research and deployment.

% \begin{itemize}
%     \item First: calibration
%     \item Second: visual servo
%     \item Third: extraction
%     \item Fourth: prediction
%     \item Fifth: infrastructure
% \end{itemize}



% Automation is rapidly propagating into our daily lives. Most notably, autonomous vehicles, but also vacuum cleaners, drones, and industrial arms are reaching high levels of autonomy. Many of these advances were made possible through massively increased parallel compute, and consequentially neural networks. In surgery and robotic surgery, however, automation advances lack somewhat behind related domains. In addition to the unstructured environment, as well as regulatory and ethic hurdles, in this thesis we argue that also technical aspects hinder further development. As the title suggests, and due to its relative simplicity, robotic endoscope camera motion automation is of immediate relevance to this work. Rule-based approaches impose a tool following assumption on the camera motion. This assumption is not clinically verified. Modern data-driven approach could help to learn more complex control policies. The technical hurdles hurdles therein are twofold. First, the unavailability of state-action pairs renders application of modern imitation learning techniques impossible. Second, currently non-robotic surgeries pave no clear path towards automation altogether.
